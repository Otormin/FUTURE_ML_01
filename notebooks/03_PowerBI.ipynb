{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294a6ddc-b992-4d68-bba5-da32f7f75e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POWER BI DATA PREPARATION - FINAL ASSEMBLY\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"POWER BI DATA PREPARATION - FINAL ASSEMBLY\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5384f9-2e34-4b9c-9089-b30de95d593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. LOADING DATA SOURCES...\n",
      "Train data: (1017209, 9)\n",
      "Store data: (1115, 10)\n",
      "Test data: (41088, 8)\n",
      "Processed data: (844392, 26)\n",
      "Forecast data: (942, 12)\n",
      "Metrics data: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# 1. LOAD ALL DATA SOURCES\n",
    "print(\"\\n1. LOADING DATA SOURCES...\")\n",
    "\n",
    "try:\n",
    "    # Load original datasets\n",
    "    train_df = pd.read_csv('../data/raw/train.csv')\n",
    "    store_df = pd.read_csv('../data/raw/store.csv')\n",
    "    test_df = pd.read_csv('../data/raw/test.csv')\n",
    "    \n",
    "    # Load processed data\n",
    "    processed_df = pd.read_csv('../data/processed/rossmann_processed.csv')\n",
    "    processed_df['Date'] = pd.to_datetime(processed_df['Date'])\n",
    "    \n",
    "    # Load forecast results\n",
    "    forecast_df = pd.read_csv('../data/forecasts/prophet_forecast_powerbi.csv')\n",
    "    forecast_df['Date'] = pd.to_datetime(forecast_df['Date'])\n",
    "    \n",
    "    # Load model metrics\n",
    "    metrics_df = pd.read_csv('../data/forecasts/model_metrics.csv')\n",
    "    \n",
    "    print(f\"Train data: {train_df.shape}\")\n",
    "    print(f\"Store data: {store_df.shape}\")\n",
    "    print(f\"Test data: {test_df.shape}\")\n",
    "    print(f\"Processed data: {processed_df.shape}\")\n",
    "    print(f\"Forecast data: {forecast_df.shape}\")\n",
    "    print(f\"Metrics data: {metrics_df.shape}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Missing file: {e}\")\n",
    "    print(\"Please ensure you've run 01_EDA.ipynb then 02_Modeling.ipynb first\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb3d7c3-27aa-4971-8bd1-a848e1ac862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. CREATING MASTER DATASET...\n",
      "Master dataset created: (942, 31)\n"
     ]
    }
   ],
   "source": [
    "# 2. CREATE MASTER DATASET FOR POWER BI\n",
    "print(\"\\n2. CREATING MASTER DATASET...\")\n",
    "\n",
    "# Start with forecast data as base (includes historical + future)\n",
    "master_df = forecast_df.copy()\n",
    "\n",
    "# Add detailed historical data where available\n",
    "historical_detail = processed_df.groupby('Date').agg({\n",
    "    'Sales': 'sum',\n",
    "    'Customers': 'sum',\n",
    "    'Open': 'mean',\n",
    "    'Promo': 'mean',\n",
    "    'StateHoliday': lambda x: (x != '0').mean(),\n",
    "    'SchoolHoliday': 'mean',\n",
    "    'Store': 'nunique',\n",
    "    'StoreType': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'a',\n",
    "    'Assortment': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'a',\n",
    "    'CompetitionDistance': 'mean',\n",
    "    'DayOfWeek': 'first',\n",
    "    'IsWeekend': 'mean',\n",
    "    'Year': 'first',\n",
    "    'Month': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge with master dataset\n",
    "master_df = master_df.merge(historical_detail, on='Date', how='left', suffixes=('', '_detail'))\n",
    "\n",
    "# Clean up column names and add missing features\n",
    "master_df['Total_Stores_Open'] = master_df['Store'].fillna(1115)  # Total stores in dataset\n",
    "master_df['Avg_Customers_Per_Store'] = master_df['Customers'] / master_df['Total_Stores_Open']\n",
    "master_df['Sales_Per_Customer'] = master_df['Actual_Sales'] / master_df['Customers']\n",
    "master_df['Promo_Penetration'] = master_df['Promo'].fillna(0.4)  # Use recent average for future\n",
    "master_df['Holiday_Penetration'] = master_df['StateHoliday'].fillna(0.05)\n",
    "\n",
    "print(f\"Master dataset created: {master_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2060ecc-df7f-44a4-8e6f-6357d77d78ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. CREATING STORE-LEVEL SUMMARIES...\n",
      "Store summary created: (1115, 10)\n"
     ]
    }
   ],
   "source": [
    "# 3. CREATE STORE-LEVEL AGGREGATIONS\n",
    "print(\"\\n3. CREATING STORE-LEVEL SUMMARIES...\")\n",
    "\n",
    "# Store performance summary\n",
    "store_summary = processed_df.groupby('Store').agg({\n",
    "    'Sales': ['sum', 'mean', 'std'],\n",
    "    'Customers': ['sum', 'mean'],\n",
    "    'StoreType': 'first',\n",
    "    'Assortment': 'first',\n",
    "    'CompetitionDistance': 'first'\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "store_summary.columns = ['_'.join(col).strip() for col in store_summary.columns.values]\n",
    "store_summary = store_summary.reset_index()\n",
    "\n",
    "# Add performance categories\n",
    "store_summary['Sales_Category'] = pd.cut(\n",
    "    store_summary['Sales_mean'], \n",
    "    bins=[0, 5000, 7000, 10000, float('inf')],\n",
    "    labels=['Low', 'Medium', 'High', 'Very High']\n",
    ")\n",
    "\n",
    "print(f\"Store summary created: {store_summary.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18e74fe-9ef0-4f30-a163-1f7051713c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. CREATING TIME-BASED SUMMARIES...\n",
      "Monthly summary: (31, 10)\n",
      "Weekly summary: (135, 7)\n",
      "Day of week summary: (7, 7)\n"
     ]
    }
   ],
   "source": [
    "# 4. CREATE TIME-BASED AGGREGATIONS\n",
    "print(\"\\n4. CREATING TIME-BASED SUMMARIES...\")\n",
    "\n",
    "# Monthly aggregations\n",
    "monthly_summary = processed_df.groupby(['Year', 'Month']).agg({\n",
    "    'Sales': ['sum', 'mean'],\n",
    "    'Customers': ['sum', 'mean'],\n",
    "    'Promo': 'mean',\n",
    "    'StateHoliday': lambda x: (x != '0').mean(),\n",
    "    'Store': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "monthly_summary.columns = ['_'.join(col).strip() for col in monthly_summary.columns.values]\n",
    "monthly_summary = monthly_summary.reset_index()\n",
    "monthly_summary['Month_Year'] = monthly_summary['Year'].astype(str) + '-' + monthly_summary['Month'].astype(str).str.zfill(2)\n",
    "\n",
    "# Weekly aggregations  \n",
    "weekly_summary = processed_df.groupby(['Year', processed_df['Date'].dt.isocalendar().week]).agg({\n",
    "    'Sales': ['sum', 'mean'],\n",
    "    'Customers': ['sum', 'mean'],\n",
    "    'Promo': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "weekly_summary.columns = ['_'.join(col).strip() for col in weekly_summary.columns.values]\n",
    "weekly_summary = weekly_summary.reset_index()\n",
    "weekly_summary.columns = ['Year', 'Week', 'Sales_sum', 'Sales_mean', 'Customers_sum', 'Customers_mean', 'Promo_mean']\n",
    "\n",
    "# Day of week patterns\n",
    "dow_summary = processed_df.groupby('DayOfWeek').agg({\n",
    "    'Sales': ['sum', 'mean', 'std'],\n",
    "    'Customers': ['sum', 'mean']\n",
    "}).round(2)\n",
    "\n",
    "dow_summary.columns = ['_'.join(col).strip() for col in dow_summary.columns.values]\n",
    "dow_summary = dow_summary.reset_index()\n",
    "dow_summary['Day_Name'] = dow_summary['DayOfWeek'].map({\n",
    "    0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday',\n",
    "    4: 'Friday', 5: 'Saturday', 6: 'Sunday'\n",
    "})\n",
    "\n",
    "print(f\"Monthly summary: {monthly_summary.shape}\")\n",
    "print(f\"Weekly summary: {weekly_summary.shape}\")\n",
    "print(f\"Day of week summary: {dow_summary.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f74375-0f45-4cd9-b3bc-7a404a5a4bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. CREATING KPI SUMMARY...\n",
      "KPI summary created: (11, 3)\n"
     ]
    }
   ],
   "source": [
    "# 5. CREATE KPI SUMMARY TABLE\n",
    "print(\"\\n5. CREATING KPI SUMMARY...\")\n",
    "\n",
    "# Calculate key business metrics\n",
    "total_historical_sales = processed_df['Sales'].sum()\n",
    "total_historical_customers = processed_df['Customers'].sum()\n",
    "avg_daily_sales = processed_df.groupby('Date')['Sales'].sum().mean()\n",
    "best_performing_store = processed_df.groupby('Store')['Sales'].mean().idxmax()\n",
    "best_store_avg_sales = processed_df.groupby('Store')['Sales'].mean().max()\n",
    "\n",
    "# Future forecasts summary\n",
    "future_forecasts = master_df[master_df['Is_Forecast'] == True]\n",
    "if len(future_forecasts) > 0:\n",
    "    forecasted_total_sales = future_forecasts['Forecasted_Sales'].sum()\n",
    "    avg_forecasted_daily_sales = future_forecasts['Forecasted_Sales'].mean()\n",
    "    forecast_period_days = len(future_forecasts)\n",
    "else:\n",
    "    forecasted_total_sales = 0\n",
    "    avg_forecasted_daily_sales = 0\n",
    "    forecast_period_days = 0\n",
    "\n",
    "# Create KPI dataframe\n",
    "kpi_summary = pd.DataFrame({\n",
    "    'KPI_Name': [\n",
    "        'Total Historical Sales',\n",
    "        'Total Historical Customers', \n",
    "        'Average Daily Sales (Historical)',\n",
    "        'Best Performing Store ID',\n",
    "        'Best Store Average Daily Sales',\n",
    "        'Forecasted Total Sales',\n",
    "        'Average Forecasted Daily Sales',\n",
    "        'Forecast Period (Days)',\n",
    "        'Model MAPE',\n",
    "        'Model MAE',\n",
    "        'Model RMSE'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"€{total_historical_sales:,.0f}\",\n",
    "        f\"{total_historical_customers:,.0f}\",\n",
    "        f\"€{avg_daily_sales:,.0f}\", \n",
    "        f\"{best_performing_store}\",\n",
    "        f\"€{best_store_avg_sales:,.0f}\",\n",
    "        f\"€{forecasted_total_sales:,.0f}\",\n",
    "        f\"€{avg_forecasted_daily_sales:,.0f}\",\n",
    "        f\"{forecast_period_days}\",\n",
    "        f\"{metrics_df[metrics_df['Metric'] == 'MAPE']['Value'].iloc[0]:.1f}%\",\n",
    "        f\"€{metrics_df[metrics_df['Metric'] == 'MAE']['Value'].iloc[0]:,.0f}\",\n",
    "        f\"€{metrics_df[metrics_df['Metric'] == 'RMSE']['Value'].iloc[0]:,.0f}\"\n",
    "    ],\n",
    "    'Category': [\n",
    "        'Historical Performance',\n",
    "        'Historical Performance',\n",
    "        'Historical Performance', \n",
    "        'Store Performance',\n",
    "        'Store Performance',\n",
    "        'Future Projections',\n",
    "        'Future Projections',\n",
    "        'Future Projections',\n",
    "        'Model Performance',\n",
    "        'Model Performance', \n",
    "        'Model Performance'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(f\"KPI summary created: {kpi_summary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96d1596-c55f-4854-a317-40ddf35d9202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. CREATING SEASONAL INSIGHTS...\n",
      "Seasonality insights: (19, 4)\n"
     ]
    }
   ],
   "source": [
    "# 6. CREATE SEASONAL INSIGHTS TABLE\n",
    "print(\"\\n6. CREATING SEASONAL INSIGHTS...\")\n",
    "\n",
    "# Monthly seasonality\n",
    "monthly_seasonality = processed_df.groupby('Month')['Sales'].mean().reset_index()\n",
    "monthly_seasonality['Month_Name'] = monthly_seasonality['Month'].map({\n",
    "    1: 'January', 2: 'February', 3: 'March', 4: 'April',\n",
    "    5: 'May', 6: 'June', 7: 'July', 8: 'August', \n",
    "    9: 'September', 10: 'October', 11: 'November', 12: 'December'\n",
    "})\n",
    "monthly_seasonality['Seasonality_Type'] = 'Monthly'\n",
    "\n",
    "# Day of week seasonality  \n",
    "dow_seasonality = dow_summary[['DayOfWeek', 'Day_Name', 'Sales_mean']].copy()\n",
    "dow_seasonality.columns = ['Period_Number', 'Period_Name', 'Sales']\n",
    "dow_seasonality['Seasonality_Type'] = 'Weekly'\n",
    "\n",
    "# Combine seasonality data\n",
    "seasonality_insights = pd.concat([\n",
    "    monthly_seasonality[['Month', 'Month_Name', 'Sales']].rename(columns={'Month': 'Period_Number', 'Month_Name': 'Period_Name'}),\n",
    "    dow_seasonality\n",
    "], ignore_index=True)\n",
    "\n",
    "print(f\"Seasonality insights: {seasonality_insights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92cc743-0816-4db8-ac22-c07ec16419f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. PERFORMING DATA QUALITY CHECKS...\n",
      "DATA QUALITY REPORT:\n",
      "\n",
      "Master Dataset:\n",
      "   • Total Rows: 942\n",
      "   • Date Range: 2013-01-01 00:00:00 to 2015-07-31 00:00:00\n",
      "   • Missing Actual Sales: 0\n",
      "   • Missing Forecasted Sales: 0\n",
      "   • Future Records: 0\n",
      "\n",
      "Store Summary:\n",
      "   • Total Stores: 1115\n",
      "   • Missing Store Types: 0\n",
      "   • Sales Categories: {'Medium': 440, 'High': 374, 'Low': 207, 'Very High': 94}\n"
     ]
    }
   ],
   "source": [
    "# 7. DATA QUALITY CHECKS\n",
    "print(\"\\n7. PERFORMING DATA QUALITY CHECKS...\")\n",
    "\n",
    "quality_checks = {\n",
    "    'Master Dataset': {\n",
    "        'Total Rows': len(master_df),\n",
    "        'Date Range': f\"{master_df['Date'].min()} to {master_df['Date'].max()}\",\n",
    "        'Missing Actual Sales': master_df['Actual_Sales'].isna().sum(),\n",
    "        'Missing Forecasted Sales': master_df['Forecasted_Sales'].isna().sum(),\n",
    "        'Future Records': (master_df['Is_Forecast'] == True).sum()\n",
    "    },\n",
    "    'Store Summary': {\n",
    "        'Total Stores': len(store_summary),\n",
    "        'Missing Store Types': store_summary['StoreType_first'].isna().sum(),\n",
    "        'Sales Categories': store_summary['Sales_Category'].value_counts().to_dict()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"DATA QUALITY REPORT:\")\n",
    "for dataset, checks in quality_checks.items():\n",
    "    print(f\"\\n{dataset}:\")\n",
    "    for check, value in checks.items():\n",
    "        print(f\"   • {check}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b98630a-ea1f-4efb-98c5-949fe592abd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8. SAVING POWER BI DATASETS...\n",
      "SAVING DATASETS:\n",
      "   master_data_powerbi.csv: (942, 31)\n",
      "   store_summary_powerbi.csv: (1115, 10)\n",
      "   monthly_summary_powerbi.csv: (31, 10)\n",
      "   weekly_summary_powerbi.csv: (135, 7)\n",
      "   day_of_week_summary_powerbi.csv: (7, 7)\n",
      "   kpi_summary_powerbi.csv: (11, 3)\n",
      "   seasonality_insights_powerbi.csv: (19, 4)\n"
     ]
    }
   ],
   "source": [
    "# 8. SAVE ALL POWER BI DATASETS\n",
    "print(\"\\n8. SAVING POWER BI DATASETS...\")\n",
    "\n",
    "# Create forecasts folder if it doesn't exist\n",
    "import os\n",
    "os.makedirs('../data/forecasts', exist_ok=True)\n",
    "\n",
    "# Save main datasets\n",
    "datasets = {\n",
    "    'master_data_powerbi.csv': master_df,\n",
    "    'store_summary_powerbi.csv': store_summary, \n",
    "    'monthly_summary_powerbi.csv': monthly_summary,\n",
    "    'weekly_summary_powerbi.csv': weekly_summary,\n",
    "    'day_of_week_summary_powerbi.csv': dow_summary,\n",
    "    'kpi_summary_powerbi.csv': kpi_summary,\n",
    "    'seasonality_insights_powerbi.csv': seasonality_insights\n",
    "}\n",
    "\n",
    "print(\"SAVING DATASETS:\")\n",
    "for filename, dataset in datasets.items():\n",
    "    filepath = f'../data/forecasts/{filename}'\n",
    "    dataset.to_csv(filepath, index=False)\n",
    "    print(f\"   {filename}: {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f795ff7-6a1d-404d-a9a3-f25812f626d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9. CREATING DATA DICTIONARY...\n",
      "Data dictionary saved: (11, 4)\n"
     ]
    }
   ],
   "source": [
    "# 9. CREATE DATA DICTIONARY\n",
    "print(\"\\n9. CREATING DATA DICTIONARY...\")\n",
    "\n",
    "data_dictionary = pd.DataFrame({\n",
    "    'Dataset': [\n",
    "        'master_data_powerbi.csv', 'master_data_powerbi.csv', 'master_data_powerbi.csv', \n",
    "        'master_data_powerbi.csv', 'master_data_powerbi.csv', 'master_data_powerbi.csv',\n",
    "        'store_summary_powerbi.csv', 'store_summary_powerbi.csv', 'store_summary_powerbi.csv',\n",
    "        'kpi_summary_powerbi.csv', 'seasonality_insights_powerbi.csv'\n",
    "    ],\n",
    "    'Column_Name': [\n",
    "        'Date', 'Actual_Sales', 'Forecasted_Sales', 'Lower_Bound', 'Upper_Bound', 'Is_Forecast',\n",
    "        'Store', 'Sales_mean', 'Sales_Category', 'KPI_Name', 'Seasonality_Type'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Date of sales record',\n",
    "        'Actual historical sales in euros',\n",
    "        'Prophet model forecasted sales in euros', \n",
    "        'Lower confidence bound for forecast',\n",
    "        'Upper confidence bound for forecast',\n",
    "        'Boolean flag: True for forecasted records',\n",
    "        'Store ID number',\n",
    "        'Average daily sales per store',\n",
    "        'Store performance category (Low/Medium/High/Very High)',\n",
    "        'Key performance indicator name',\n",
    "        'Type of seasonality (Monthly/Weekly)'\n",
    "    ],\n",
    "    'Data_Type': [\n",
    "        'Date', 'Numeric', 'Numeric', 'Numeric', 'Numeric', 'Boolean',\n",
    "        'Numeric', 'Numeric', 'Categorical', 'Text', 'Categorical'  \n",
    "    ]\n",
    "})\n",
    "\n",
    "data_dictionary.to_csv('../data/forecasts/data_dictionary.csv', index=False)\n",
    "print(f\"Data dictionary saved: {data_dictionary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9969a4f-bab4-4900-80c7-1fcd644b6caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10. CREATING POWER BI IMPORT GUIDE...\n",
      "Power BI import guide created\n"
     ]
    }
   ],
   "source": [
    "# 10. CREATE POWER BI IMPORT GUIDE\n",
    "print(\"\\n10. CREATING POWER BI IMPORT GUIDE...\")\n",
    "\n",
    "powerbi_guide = \"\"\"\n",
    "# POWER BI IMPORT GUIDE - ROSSMANN SALES FORECASTING\n",
    "\n",
    "## DATASETS TO IMPORT:\n",
    "\n",
    "### 1. MAIN FORECAST DATA\n",
    "**File:** master_data_powerbi.csv\n",
    "**Purpose:** Primary dataset with historical sales + forecasts\n",
    "**Key Columns:** Date, Actual_Sales, Forecasted_Sales, Is_Forecast\n",
    "**Relationships:** Primary table for time-based analysis\n",
    "\n",
    "### 2. STORE PERFORMANCE \n",
    "**File:** store_summary_powerbi.csv  \n",
    "**Purpose:** Store-level performance metrics\n",
    "**Key Columns:** Store, Sales_mean, Sales_Category, StoreType_first\n",
    "**Relationships:** Link to master data via Store ID\n",
    "\n",
    "### 3. TIME AGGREGATIONS\n",
    "**Files:** monthly_summary_powerbi.csv, weekly_summary_powerbi.csv, day_of_week_summary_powerbi.csv\n",
    "**Purpose:** Pre-calculated time-based summaries for performance\n",
    "**Key Columns:** Various time periods with sales summaries\n",
    "\n",
    "### 4. KPI DASHBOARD\n",
    "**File:** kpi_summary_powerbi.csv\n",
    "**Purpose:** Key business metrics for dashboard cards\n",
    "**Key Columns:** KPI_Name, Value, Category\n",
    "\n",
    "### 5. SEASONALITY ANALYSIS\n",
    "**File:** seasonality_insights_powerbi.csv\n",
    "**Purpose:** Monthly and weekly seasonal patterns  \n",
    "**Key Columns:** Period_Name, Sales, Seasonality_Type\n",
    "\n",
    "## SUGGESTED DASHBOARD PAGES:\n",
    "\n",
    "### PAGE 1: EXECUTIVE SUMMARY\n",
    "- KPI cards (Total Sales, Forecast Accuracy, etc.)\n",
    "- Sales trend line (Actual vs Forecasted)\n",
    "- YoY growth metrics\n",
    "- Top performing stores\n",
    "\n",
    "### PAGE 2: SALES FORECASTING\n",
    "- Interactive forecast chart with confidence intervals\n",
    "- Filter by date range\n",
    "- Forecast vs actual comparison\n",
    "- Seasonal decomposition\n",
    "\n",
    "### PAGE 3: STORE PERFORMANCE\n",
    "- Store performance matrix\n",
    "- Geographic analysis (if coordinates available)\n",
    "- Store type comparisons\n",
    "- Bottom/Top performers\n",
    "\n",
    "### PAGE 4: SEASONAL INSIGHTS  \n",
    "- Monthly seasonality patterns\n",
    "- Day-of-week analysis\n",
    "- Holiday impact analysis\n",
    "- Promotion effectiveness\n",
    "\n",
    "## POWER BI SETUP STEPS:\n",
    "\n",
    "1. **Import Data:**\n",
    "   - Get Data > Text/CSV\n",
    "   - Import all CSV files from /data/forecasts/\n",
    "   - Ensure Date columns are recognized as Date type\n",
    "\n",
    "2. **Create Relationships:**\n",
    "   - Link master_data to store_summary via Store column\n",
    "   - Set up date table relationships\n",
    "\n",
    "3. **Create Measures:**\n",
    "   - Sales Growth % = (Current Period Sales - Previous Period Sales) / Previous Period Sales\n",
    "   - Forecast Accuracy = 1 - ABS(Actual - Forecast) / Actual\n",
    "   - YTD Sales = TOTALYTD(SUM(Sales), Date)\n",
    "\n",
    "4. **Add Filters:**\n",
    "   - Date range slicer\n",
    "   - Store type filter\n",
    "   - Is_Forecast toggle\n",
    "\n",
    "## VISUALIZATION RECOMMENDATIONS:\n",
    "\n",
    "- **Line Charts:** Time series with dual axis for actual vs forecast\n",
    "- **Cards:** KPI values with trend indicators\n",
    "- **Bar Charts:** Store performance rankings\n",
    "- **Heat Maps:** Seasonal patterns by month/day\n",
    "- **Scatter Plots:** Forecast accuracy analysis\n",
    "\n",
    "## DESIGN TIPS:\n",
    "\n",
    "- Use consistent color scheme (blue for actual, orange for forecast)\n",
    "- Add conditional formatting for performance categories\n",
    "- Include tooltips with additional context\n",
    "- Use bookmarks for different view states\n",
    "- Add export functionality for reports\n",
    "\n",
    "## ADVANCED FEATURES:\n",
    "\n",
    "- **What-If Parameters:** Adjust promotion/holiday impacts\n",
    "- **Drill-Through Pages:** Store-level detailed analysis\n",
    "- **Custom Visuals:** Prophet forecast decomposition\n",
    "- **Alerts:** Set up data-driven alerts for significant changes\n",
    "\n",
    "## DATA REFRESH:\n",
    "\n",
    "- Set up scheduled refresh if connecting to live data source\n",
    "- Update forecast models monthly for best accuracy\n",
    "- Monitor data quality with automated checks\n",
    "\n",
    "---\n",
    "Generated by Rossmann Sales Forecasting Pipeline\n",
    "Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "\"\"\"\n",
    "\n",
    "with open('../data/forecasts/PowerBI_Import_Guide.md', 'w') as f:\n",
    "    f.write(powerbi_guide)\n",
    "\n",
    "print(\"Power BI import guide created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a382cc59-ff57-4cab-b741-948b3e55016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11. FINAL VALIDATION...\n",
      "FINAL VALIDATION RESULTS:\n",
      "   • Total datasets created: 7\n",
      "   • Date range coverage: 2013-01-01 00:00:00 to 2015-07-31 00:00:00\n",
      "   • Missing dates in master data: 0\n",
      "   • Historical records: 942\n",
      "   • Forecast records: 0\n",
      "   • Stores covered: 1115\n",
      "File manifest created: (9, 3)\n",
      "\n",
      "POWER BI DATA PREPARATION COMPLETE!\n",
      "============================================================\n",
      "ALL FILES READY FOR POWER BI:\n",
      "   /data/forecasts/ contains all CSV files\n",
      "   PowerBI_Import_Guide.md has setup instructions\n",
      "   data_dictionary.csv explains all columns\n",
      "   file_manifest.csv lists all deliverables\n",
      "\n",
      " NEXT STEPS:\n",
      "   1. Open Power BI Desktop\n",
      "   2. Import CSV files from ../data/forecasts/\n",
      "   3. Follow the PowerBI_Import_Guide.md instructions\n",
      "   4. Build your interactive forecasting dashboard!\n",
      "   5. Share insights with business stakeholders\n",
      "\n",
      " PROJECT COMPLETE - READY FOR BUSINESS IMPACT!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 11. FINAL SUMMARY AND VALIDATION\n",
    "print(\"\\n11. FINAL VALIDATION...\")\n",
    "\n",
    "# Validate data continuity\n",
    "date_gaps = pd.date_range(start=master_df['Date'].min(), \n",
    "                         end=master_df['Date'].max(), \n",
    "                         freq='D').difference(master_df['Date'])\n",
    "\n",
    "print(\"FINAL VALIDATION RESULTS:\")\n",
    "print(f\"   • Total datasets created: {len(datasets)}\")\n",
    "print(f\"   • Date range coverage: {master_df['Date'].min()} to {master_df['Date'].max()}\")\n",
    "print(f\"   • Missing dates in master data: {len(date_gaps)}\")\n",
    "print(f\"   • Historical records: {(master_df['Is_Forecast'] == False).sum()}\")\n",
    "print(f\"   • Forecast records: {(master_df['Is_Forecast'] == True).sum()}\")\n",
    "print(f\"   • Stores covered: {processed_df['Store'].nunique()}\")\n",
    "\n",
    "# Create final file manifest\n",
    "file_manifest = pd.DataFrame({\n",
    "    'Filename': list(datasets.keys()) + ['data_dictionary.csv', 'PowerBI_Import_Guide.md'],\n",
    "    'Purpose': [\n",
    "        'Main forecast dataset with historical + predicted sales',\n",
    "        'Store-level performance summary and categories', \n",
    "        'Monthly aggregated sales and metrics',\n",
    "        'Weekly aggregated sales and trends',\n",
    "        'Day-of-week patterns and seasonality',\n",
    "        'Key performance indicators for dashboard cards',\n",
    "        'Seasonal insights for monthly/weekly patterns',\n",
    "        'Data dictionary explaining all columns',\n",
    "        'Step-by-step Power BI setup guide'\n",
    "    ],\n",
    "    'Record_Count': [\n",
    "        len(master_df), len(store_summary), len(monthly_summary), \n",
    "        len(weekly_summary), len(dow_summary), len(kpi_summary),\n",
    "        len(seasonality_insights), len(data_dictionary), 'N/A'\n",
    "    ]\n",
    "})\n",
    "\n",
    "file_manifest.to_csv('../data/forecasts/file_manifest.csv', index=False)\n",
    "print(f\"File manifest created: {file_manifest.shape}\")\n",
    "\n",
    "print(\"\\nPOWER BI DATA PREPARATION COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ALL FILES READY FOR POWER BI:\")\n",
    "print(\"   /data/forecasts/ contains all CSV files\")\n",
    "print(\"   PowerBI_Import_Guide.md has setup instructions\")\n",
    "print(\"   data_dictionary.csv explains all columns\")\n",
    "print(\"   file_manifest.csv lists all deliverables\")\n",
    "\n",
    "print(f\"\\n NEXT STEPS:\")\n",
    "print(\"   1. Open Power BI Desktop\")\n",
    "print(\"   2. Import CSV files from ../data/forecasts/\")\n",
    "print(\"   3. Follow the PowerBI_Import_Guide.md instructions\")\n",
    "print(\"   4. Build your interactive forecasting dashboard!\")\n",
    "print(\"   5. Share insights with business stakeholders\")\n",
    "\n",
    "print(\"\\n PROJECT COMPLETE - READY FOR BUSINESS IMPACT!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
